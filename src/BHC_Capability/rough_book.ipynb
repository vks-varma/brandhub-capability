{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variable\n",
    "config_file_path = \"config.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def config_loading(config_path:str):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "\n",
    "def build_output_paths(config):\n",
    "    \"\"\"\n",
    "    Build full paths for output files based on the configuration.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Configuration dictionary with keys:\n",
    "            - root_path: Root directory path.\n",
    "            - output_folder: Folder where output files will be saved.\n",
    "            - filtered_data_filename: Filename for filtered data.\n",
    "            - no_null_imputed_data_filename: Filename for no-null imputed data.\n",
    "            - scaled_data_filename: Filename for scaled data.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with keys 'filtered_data_path', 'no_null_imputed_data_path',\n",
    "              and 'scaled_data_path', containing the full paths for the respective files.\n",
    "    \"\"\"\n",
    "    # Get the root path and output folder\n",
    "    root_path = config[\"root_path\"]\n",
    "    output_folder = config[\"output_folder\"]\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    output_path = os.path.join(root_path, output_folder)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Build full paths for the output files\n",
    "    paths = {\n",
    "        \"filtered_data_path\": os.path.join(\n",
    "            output_path, config[\"filtered_data\"]\n",
    "        ),\n",
    "        \"no_null_imputed_data_path\": os.path.join(\n",
    "            output_path, config[\"no_null_imputed_data\"]\n",
    "        ),\n",
    "        \"scaled_data_path\": os.path.join(output_path, config[\"scaled_data\"]),\n",
    "    }\n",
    "\n",
    "    return paths\n",
    "\n",
    "def date_dv_columns_check(data: pd.DataFrame, config: dict):\n",
    "    required_columns = [config['date_column'], config['dv_column']] + config['data_prep_group_var']\n",
    "    missing_columns = [col for col in required_columns if col not in data.columns]\n",
    "\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"The following required columns are missing from the DataFrame: {missing_columns}\")\n",
    "    else:\n",
    "        print(\"All required columns are present in the DataFrame.\")\n",
    "\n",
    "def data_date_conversion(data:pd.DataFrame, config:dict):\n",
    "    data[config['date_column']] = pd.to_datetime(data[config['date_column']], format=config['date_format'])\n",
    "    return data\n",
    "\n",
    "def idv_list_loading(config:dict):\n",
    "    idv = pd.read_csv(config['idv_list'])\n",
    "    return idv\n",
    "\n",
    "def check_idv_columns_in_data(data:pd.DataFrame, idv_list:pd.DataFrame, column_name:str, config):\n",
    "    \"\"\"\n",
    "    Checks if all columns in df1 are present as rows in a specified column of df2.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The first DataFrame whose columns need to be checked.\n",
    "    - idv_list (pd.DataFrame): The second DataFrame with the reference column.\n",
    "    - column_name (str): The column in df2 that should contain all column names of df1.\n",
    "\n",
    "    Returns:\n",
    "    - None: If all columns are found, the function silently passes.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If any columns are missing, it raises an error with the missing columns.\n",
    "    \"\"\"\n",
    "    # Get the list of columns from df1\n",
    "    df1_columns = set(data.columns)\n",
    "\n",
    "    # Get the unique values in the specified column of df2\n",
    "    df2_values = set(idv_list[column_name])\n",
    "\n",
    "    # Find the missing columns\n",
    "    missing_columns = df2_values - df1_columns\n",
    "\n",
    "    # Raise an error if there are missing columns\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"The following independent variables are missing in data: {missing_columns}\")\n",
    "    else:\n",
    "        print(\"All independent variables in idv_list are present in the data.\")\n",
    "    required_columns = [config['date_column'], config['dv_column']] + config['data_prep_group_var']\n",
    "    return data[required_columns + list(df2_values)]\n",
    "\n",
    "def data_loading(config:dict):\n",
    "\n",
    "    input_data = pd.read_csv(config['input_data'])\n",
    "    date_dv_columns_check(input_data, config)\n",
    "    data = data_date_conversion(input_data, config)\n",
    "    idv_list = idv_list_loading(config)\n",
    "    data = check_idv_columns_in_data(data, idv_list, \"idv\", config)\n",
    "\n",
    "    return data, idv_list\n",
    "\n",
    "def column_arrangement(config: dict, idv_list:pd.DataFrame):\n",
    "    sorted_idv_list = sorted(idv_list['idv'].tolist())\n",
    "    sorted_idv_list\n",
    "    column_arrangement = [config['date_column']] + config['data_prep_group_var'] + sorted_idv_list + [config['dv_column']]\n",
    "    return column_arrangement\n",
    "\n",
    "def filter_by_date_range(data:pd.DataFrame, config:dict):\n",
    "    \"\"\"Filtering date range for the data processing and further analysis\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): Harmonized_processed_data to filter out the date range\n",
    "        config (dict): configuration dictionary\n",
    "    Returns:\n",
    "        DataFrame: Data with filtered date range\n",
    "    \"\"\"\n",
    "    data[\"date\"] = pd.to_datetime(data[\"date\"], utc=False)\n",
    "\n",
    "    # Print the minimum and maximum date values for verification\n",
    "    print(\"Minimum date:\", data[\"date\"].min(skipna=True))\n",
    "    print(\"Maximum date:\", data[\"date\"].max(skipna=True))\n",
    "\n",
    "    # Define the date range from run_config\n",
    "    date1 = pd.to_datetime(config['start_date'], format=\"%Y-%m-%d\")\n",
    "    date2 = pd.to_datetime(config['end_date'], format=\"%Y-%m-%d\")\n",
    "\n",
    "    # Filter the DataFrame based on the date range\n",
    "    data = data[(data[\"date\"] >= date1) & (data[\"date\"] <= date2)]\n",
    "    if data[config['dv_column']].isna().sum() != 0:\n",
    "        raise ValueError(f\"The dependent variable {config['dv_column']} is having null values\")\n",
    "    return data\n",
    "\n",
    "### preprocessing functions ####\n",
    "\n",
    "def cap_values(df, col, min_val, max_val):\n",
    "    df[col] = df[col].astype(float).clip(lower=min_val, upper=max_val)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_unique_combinations(df: pd.DataFrame, columns: list):\n",
    "    \"\"\"\n",
    "    Get unique combinations of values in the specified columns of a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame to extract combinations from.\n",
    "    - columns (list): A list of column names to consider.\n",
    "\n",
    "    Returns:\n",
    "    - list of dict: Each dictionary represents a unique combination of column-value pairs.\n",
    "    \"\"\"\n",
    "    # Check if the specified columns exist in the DataFrame\n",
    "    missing_columns = [col for col in columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"The following columns are missing from the DataFrame: {missing_columns}\")\n",
    "\n",
    "    # Extract unique rows for the specified columns\n",
    "    unique_combinations = df[columns].drop_duplicates().to_dict(orient=\"records\")\n",
    "\n",
    "    return unique_combinations\n",
    "\n",
    "\n",
    "def drop_rows_with_nulls(df: pd.DataFrame, group_by_columns: list, null_threshold: float):\n",
    "    \"\"\"\n",
    "    Drop rows for specific combinations of columns where more than 50% of the 'value' column is null.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame to process.\n",
    "    - group_by_columns (list): List of columns to group by.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with rows removed based on the condition.\n",
    "    \"\"\"\n",
    "    # Step 1: Group by specified columns\n",
    "    grouped = df.groupby(group_by_columns)\n",
    "\n",
    "    # Step 2: Calculate the percentage of nulls for each group\n",
    "    null_percentage = grouped['value'].apply(lambda x: x.isnull().mean())\n",
    "\n",
    "    # Step 3: Identify groups with more than 50% null values\n",
    "    groups_to_drop = null_percentage[null_percentage > null_threshold].index\n",
    "\n",
    "    # Step 4: Filter out rows belonging to the identified groups\n",
    "    filtered_df = df[~df.set_index(group_by_columns).index.isin(groups_to_drop)]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "def impute_groups(df: pd.DataFrame, group_by_columns: list, null_threshold: float, imputation_method: str = 'mean'):\n",
    "    \"\"\"\n",
    "    Drop rows for specific combinations of columns where more than the specified percentage of the 'value' column is null,\n",
    "    and impute missing values for groups with less than the threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame to process.\n",
    "    - group_by_columns (list): List of columns to group by.\n",
    "    - null_threshold (float): The threshold of null percentage for which rows will be dropped.\n",
    "    - imputation_method (str): The method for imputing missing values ('mean', 'median', 'mode').\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with rows removed and missing values imputed.\n",
    "    \"\"\"\n",
    "    # Step 1: Group by specified columns\n",
    "    grouped = df.groupby(group_by_columns)\n",
    "\n",
    "    # Step 2: Calculate the percentage of nulls for each group\n",
    "    null_percentage = grouped['value'].apply(lambda x: x.isnull().mean())\n",
    "\n",
    "    # Step 3: Identify groups with more than the null threshold percentage of null values\n",
    "    groups_to_drop = null_percentage[null_percentage > null_threshold].index\n",
    "    groups_to_drop_list = groups_to_drop.to_list()\n",
    "\n",
    "    print(groups_to_drop_list)\n",
    "    # Step 4: Filter out rows belonging to the identified groups\n",
    "    df_filtered = df[~df.set_index(group_by_columns).index.isin(groups_to_drop)]\n",
    "\n",
    "    # Step 5: Impute missing values for the remaining groups (those with less than the threshold null percentage)\n",
    "    for group, group_df in df_filtered.groupby(group_by_columns):\n",
    "        if group not in groups_to_drop:\n",
    "            if imputation_method == 'mean':\n",
    "                fill_value = group_df['value'].mean()\n",
    "            elif imputation_method == 'median':\n",
    "                fill_value = group_df['value'].median()\n",
    "            elif imputation_method == 'mode':\n",
    "                fill_value = group_df['value'].mode()[0]\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported imputation method: {imputation_method}\")\n",
    "\n",
    "            # Impute the missing values in the group\n",
    "            df_filtered.loc[group_df.index, 'value'] = group_df['value'].fillna(fill_value)\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "# Scaling Function\n",
    "def scale_metrics(melted_data, idv_list, config):\n",
    "    def apply_scaling(group):\n",
    "        metric_name = group['metric'].iloc[0]\n",
    "        # Skip scaling for the dependent variable\n",
    "        if metric_name == config['dv_column']:\n",
    "            group['value'] = group['value']\n",
    "            return group\n",
    "        if config['scaling'] == 'minmax':\n",
    "            # Min-Max Scaling: Scale between 0 and 1\n",
    "            min_val = group['value'].min()\n",
    "            max_val = group['value'].max()\n",
    "            group['value'] = (group['value'] - min_val) / (max_val - min_val)\n",
    "\n",
    "        elif config['scaling'] == 'standard':\n",
    "            # Standard Scaling: Scale with mean and standard deviation\n",
    "            mean_val = group['value'].mean()\n",
    "            std_dev = group['value'].std()\n",
    "            group['value'] = (group['value'] - mean_val) / std_dev\n",
    "\n",
    "        elif config['scaling'] == 'custom':\n",
    "            # Custom Scaling: Use min and max from df2\n",
    "            custom_min = idv_list.loc[idv_list['idv'] == metric_name, 'min'].values[0]\n",
    "            custom_max = idv_list.loc[idv_list['idv'] == metric_name, 'max'].values[0]\n",
    "            print((metric_name, custom_max, custom_min))\n",
    "            group['value'] = (group['value'] - custom_min) / (custom_max - custom_min)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid scaling method. Choose 'minmax', 'standard', or 'custom'.\")\n",
    "\n",
    "        return group\n",
    "\n",
    "    # Group by 'metric' and apply scaling\n",
    "    scaled_df = melted_data.groupby('metric', group_keys=False).apply(apply_scaling)\n",
    "    return scaled_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required columns are present in the DataFrame.\n",
      "All independent variables in idv_list are present in the data.\n",
      "Minimum date: 2017-01-07 00:00:00\n",
      "Maximum date: 2025-01-11 00:00:00\n"
     ]
    }
   ],
   "source": [
    "config = config_loading(config_file_path)\n",
    "data, idv_list = data_loading(config)\n",
    "filtered_data = filter_by_date_range(data, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_data': 'D:\\\\BRAND_HUB_PROJECT\\\\brandhub-capability\\\\src\\\\BHC_Capability\\\\data\\\\input_data_refined_4.csv',\n",
       " 'idv_list': 'D:\\\\BRAND_HUB_PROJECT\\\\brandhub-capability\\\\src\\\\BHC_Capability\\\\data\\\\idv_list_.csv',\n",
       " 'granularity': 'weekly',\n",
       " 'data_prep_group_var': ['brand', 'category'],\n",
       " 'date_column': 'date',\n",
       " 'date_format': '%d-%m-%Y',\n",
       " 'start_date': '2022-08-01',\n",
       " 'end_date': '2024-06-01',\n",
       " 'dv_column': 'market_share',\n",
       " 'null_percentage': 0.5,\n",
       " 'scaling': 'custom',\n",
       " 'root_path': './',\n",
       " 'output_folder': 'output',\n",
       " 'filtered_data': 'filtered_data.csv',\n",
       " 'no_null_imputed_data': 'no_null_imputed_data.csv',\n",
       " 'scaled_data': 'scaled_data.csv'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"BEGGIN'\", 'DOG FOOD', 'directions_brand_attributes_always_seems_to_be_doing_something_new_mean'), (\"BEGGIN'\", 'DOG FOOD', 'directions_brand_attributes_creates_excitement_and_eagerness_at_mealtime_mean'), (\"BEGGIN'\", 'DOG FOOD', 'directions_brand_attributes_creates_playful_moments_with_my_cat_mean'), (\"BEGGIN'\", 'DOG FOOD', 'directions_brand_attributes_has_a_taste_my_cat_enjoys_mean'), (\"BEGGIN'\", 'DOG FOOD', 'directions_brand_attributes_has_a_taste_my_dog_enjoys_mean'), (\"BEGGIN'\", 'DOG FOOD', 'directions_brand_attributes_has_craveable_treats_that_my_cat_comes_running_for_mean'), (\"BEGGIN'\", 'DOG FOOD', 'directions_brand_attributes_has_the_most_satisfying_and_hearty_dog_treats_mean'), (\"BEGGIN'\", 'DOG FOOD', 'directions_brand_attributes_has_treats_that_contain_wholesome_ingredients_mean'), (\"BEGGIN'\", 'DOG FOOD', 'directions_brand_attributes_has_treats_that_have_an_appealing_package_mean'), (\"BEGGIN'\", 'DOG FOOD', 'directions_brand_attributes_is_a_brand_i_do_not_trust_to_feed_to_my_pet_mean_inverse'), (\"BEGGIN'\", 'DOG FOOD', 'directions_brand_attributes_is_a_brand_i_would_pay_more_for_mean'), (\"BEGGIN'\", 'DOG FOOD', 'directions_brand_attributes_is_available_in_different_forms_for_different_occasions_mean'), (\"BEGGIN'\", 'DOG FOOD', 'directions_brand_attributes_is_often_available_on_promotion_or_deal_mean'), (\"BEGGIN'\", 'DOG FOOD', 'directions_brand_attributes_provides_all_the_variety_my_cat_wants_mean'), (\"BEGGIN'\", 'DOG FOOD', 'directions_brand_attributes_understands_the_relationship_between_me_and_my_cat_mean'), (\"BEGGIN'\", 'DOG FOOD', 'directions_brand_attributes_understands_the_relationship_between_me_and_my_dog_mean'), (\"BEGGIN'\", 'DOG FOOD', 'ratings_reviews_review_sentiment_score_health_benefits'), (\"BEGGIN'\", 'DOG FOOD', 'ratings_reviews_review_sentiment_score_ingredients'), ('BLUE BUFFALO', 'CAT FOOD', 'directions_brand_attributes_creates_excitement_and_eagerness_at_mealtime_mean'), ('BLUE BUFFALO', 'CAT FOOD', 'directions_brand_attributes_has_a_taste_my_dog_enjoys_mean'), ('BLUE BUFFALO', 'CAT FOOD', 'directions_brand_attributes_has_the_most_satisfying_and_hearty_dog_treats_mean'), ('BLUE BUFFALO', 'CAT FOOD', 'directions_brand_attributes_has_treats_i_could_feed_my_dog_everyday_mean'), ('BLUE BUFFALO', 'CAT FOOD', 'directions_brand_attributes_has_treats_that_have_an_appealing_package_mean'), ('BLUE BUFFALO', 'CAT FOOD', 'directions_brand_attributes_helps_me_connect_with_my_dog_mean'), ('BLUE BUFFALO', 'CAT FOOD', 'directions_brand_attributes_offers_a_flavors_that_appeals_to_my_dogs_taste_mean'), ('BLUE BUFFALO', 'CAT FOOD', 'directions_brand_attributes_understands_the_relationship_between_me_and_my_dog_mean'), ('BLUE BUFFALO', 'CAT FOOD', 'search_searchvolume_share'), ('BLUE BUFFALO', 'DOG FOOD', 'directions_brand_attributes_creates_playful_moments_with_my_cat_mean'), ('BLUE BUFFALO', 'DOG FOOD', 'directions_brand_attributes_has_a_taste_my_cat_enjoys_mean'), ('BLUE BUFFALO', 'DOG FOOD', 'directions_brand_attributes_has_craveable_treats_that_my_cat_comes_running_for_mean'), ('BLUE BUFFALO', 'DOG FOOD', 'directions_brand_attributes_has_the_most_satisfying_and_hearty_dog_treats_mean'), ('BLUE BUFFALO', 'DOG FOOD', 'directions_brand_attributes_has_treats_that_contain_wholesome_ingredients_mean'), ('BLUE BUFFALO', 'DOG FOOD', 'directions_brand_attributes_has_treats_that_have_an_appealing_package_mean'), ('BLUE BUFFALO', 'DOG FOOD', 'directions_brand_attributes_is_available_in_different_forms_for_different_occasions_mean'), ('BLUE BUFFALO', 'DOG FOOD', 'directions_brand_attributes_provides_all_the_variety_my_cat_wants_mean'), ('BLUE BUFFALO', 'DOG FOOD', 'directions_brand_attributes_understands_the_relationship_between_me_and_my_cat_mean'), ('BLUE BUFFALO', 'DOG FOOD', 'search_searchvolume_share'), ('DENTALIFE', 'CAT FOOD', 'directions_brand_attributes_always_seems_to_be_doing_something_new_mean'), ('DENTALIFE', 'CAT FOOD', 'directions_brand_attributes_creates_excitement_and_eagerness_at_mealtime_mean'), ('DENTALIFE', 'CAT FOOD', 'directions_brand_attributes_has_a_taste_my_cat_enjoys_mean'), ('DENTALIFE', 'CAT FOOD', 'directions_brand_attributes_has_a_taste_my_dog_enjoys_mean'), ('DENTALIFE', 'CAT FOOD', 'directions_brand_attributes_has_the_most_satisfying_and_hearty_dog_treats_mean'), ('DENTALIFE', 'CAT FOOD', 'directions_brand_attributes_has_treats_i_could_feed_my_dog_everyday_mean'), ('DENTALIFE', 'CAT FOOD', 'directions_brand_attributes_has_treats_that_have_an_appealing_package_mean'), ('DENTALIFE', 'CAT FOOD', 'directions_brand_attributes_helps_me_connect_with_my_dog_mean'), ('DENTALIFE', 'CAT FOOD', 'directions_brand_attributes_is_a_brand_i_would_pay_more_for_mean'), ('DENTALIFE', 'CAT FOOD', 'directions_brand_attributes_offers_a_flavors_that_appeals_to_my_dogs_taste_mean'), ('DENTALIFE', 'CAT FOOD', 'directions_brand_attributes_provides_all_the_variety_my_cat_wants_mean'), ('DENTALIFE', 'CAT FOOD', 'directions_brand_attributes_understands_the_relationship_between_me_and_my_cat_mean'), ('DENTALIFE', 'CAT FOOD', 'directions_brand_attributes_understands_the_relationship_between_me_and_my_dog_mean'), ('DENTALIFE', 'CAT FOOD', 'ratings_reviews_positive_ratings_percentage'), ('DENTALIFE', 'CAT FOOD', 'ratings_reviews_review_sentiment_score_ingredients'), ('DENTALIFE', 'CAT FOOD', 'ratings_reviews_review_sentiment_score_value_for_the_money'), ('DENTALIFE', 'DOG FOOD', 'directions_brand_attributes_always_seems_to_be_doing_something_new_mean'), ('DENTALIFE', 'DOG FOOD', 'directions_brand_attributes_creates_excitement_and_eagerness_at_mealtime_mean'), ('DENTALIFE', 'DOG FOOD', 'directions_brand_attributes_creates_playful_moments_with_my_cat_mean'), ('DENTALIFE', 'DOG FOOD', 'directions_brand_attributes_has_a_taste_my_cat_enjoys_mean'), ('DENTALIFE', 'DOG FOOD', 'directions_brand_attributes_has_a_taste_my_dog_enjoys_mean'), ('DENTALIFE', 'DOG FOOD', 'directions_brand_attributes_has_craveable_treats_that_my_cat_comes_running_for_mean'), ('DENTALIFE', 'DOG FOOD', 'directions_brand_attributes_has_the_most_satisfying_and_hearty_dog_treats_mean'), ('DENTALIFE', 'DOG FOOD', 'directions_brand_attributes_has_treats_that_contain_wholesome_ingredients_mean'), ('DENTALIFE', 'DOG FOOD', 'directions_brand_attributes_has_treats_that_have_an_appealing_package_mean'), ('DENTALIFE', 'DOG FOOD', 'directions_brand_attributes_is_a_brand_i_do_not_trust_to_feed_to_my_pet_mean_inverse'), ('DENTALIFE', 'DOG FOOD', 'directions_brand_attributes_is_a_brand_i_would_pay_more_for_mean'), ('DENTALIFE', 'DOG FOOD', 'directions_brand_attributes_is_available_in_different_forms_for_different_occasions_mean'), ('DENTALIFE', 'DOG FOOD', 'directions_brand_attributes_is_often_available_on_promotion_or_deal_mean'), ('DENTALIFE', 'DOG FOOD', 'directions_brand_attributes_provides_all_the_variety_my_cat_wants_mean'), ('DENTALIFE', 'DOG FOOD', 'directions_brand_attributes_understands_the_relationship_between_me_and_my_cat_mean'), ('DENTALIFE', 'DOG FOOD', 'directions_brand_attributes_understands_the_relationship_between_me_and_my_dog_mean'), ('DENTALIFE', 'DOG FOOD', 'ratings_reviews_review_sentiment_score_ingredients'), ('PEDIGREE', 'DOG FOOD', 'directions_brand_attributes_creates_playful_moments_with_my_cat_mean'), ('PEDIGREE', 'DOG FOOD', 'directions_brand_attributes_has_a_taste_my_cat_enjoys_mean'), ('PEDIGREE', 'DOG FOOD', 'directions_brand_attributes_has_craveable_treats_that_my_cat_comes_running_for_mean'), ('PEDIGREE', 'DOG FOOD', 'directions_brand_attributes_has_the_most_satisfying_and_hearty_dog_treats_mean'), ('PEDIGREE', 'DOG FOOD', 'directions_brand_attributes_has_treats_i_could_feed_my_dog_everyday_mean'), ('PEDIGREE', 'DOG FOOD', 'directions_brand_attributes_has_treats_that_contain_wholesome_ingredients_mean'), ('PEDIGREE', 'DOG FOOD', 'directions_brand_attributes_has_treats_that_have_an_appealing_package_mean'), ('PEDIGREE', 'DOG FOOD', 'directions_brand_attributes_helps_me_connect_with_my_dog_mean'), ('PEDIGREE', 'DOG FOOD', 'directions_brand_attributes_is_available_in_different_forms_for_different_occasions_mean'), ('PEDIGREE', 'DOG FOOD', 'directions_brand_attributes_offers_a_flavors_that_appeals_to_my_dogs_taste_mean'), ('PEDIGREE', 'DOG FOOD', 'directions_brand_attributes_provides_all_the_variety_my_cat_wants_mean'), ('PEDIGREE', 'DOG FOOD', 'directions_brand_attributes_understands_the_relationship_between_me_and_my_cat_mean'), ('SHEBA', 'CAT FOOD', 'directions_brand_attributes_creates_excitement_and_eagerness_at_mealtime_mean'), ('SHEBA', 'CAT FOOD', 'directions_brand_attributes_has_a_taste_my_dog_enjoys_mean'), ('SHEBA', 'CAT FOOD', 'directions_brand_attributes_has_the_most_satisfying_and_hearty_dog_treats_mean'), ('SHEBA', 'CAT FOOD', 'directions_brand_attributes_has_treats_i_could_feed_my_dog_everyday_mean'), ('SHEBA', 'CAT FOOD', 'directions_brand_attributes_has_treats_that_have_an_appealing_package_mean'), ('SHEBA', 'CAT FOOD', 'directions_brand_attributes_helps_me_connect_with_my_dog_mean'), ('SHEBA', 'CAT FOOD', 'directions_brand_attributes_offers_a_flavors_that_appeals_to_my_dogs_taste_mean'), ('SHEBA', 'CAT FOOD', 'directions_brand_attributes_understands_the_relationship_between_me_and_my_dog_mean'), ('TEMPTATIONS', 'CAT FOOD', 'directions_brand_attributes_always_seems_to_be_doing_something_new_mean'), ('TEMPTATIONS', 'CAT FOOD', 'directions_brand_attributes_creates_excitement_and_eagerness_at_mealtime_mean'), ('TEMPTATIONS', 'CAT FOOD', 'directions_brand_attributes_has_a_taste_my_cat_enjoys_mean'), ('TEMPTATIONS', 'CAT FOOD', 'directions_brand_attributes_has_a_taste_my_dog_enjoys_mean'), ('TEMPTATIONS', 'CAT FOOD', 'directions_brand_attributes_has_the_most_satisfying_and_hearty_dog_treats_mean'), ('TEMPTATIONS', 'CAT FOOD', 'directions_brand_attributes_has_treats_i_could_feed_my_dog_everyday_mean'), ('TEMPTATIONS', 'CAT FOOD', 'directions_brand_attributes_has_treats_that_have_an_appealing_package_mean'), ('TEMPTATIONS', 'CAT FOOD', 'directions_brand_attributes_helps_me_connect_with_my_dog_mean'), ('TEMPTATIONS', 'CAT FOOD', 'directions_brand_attributes_is_a_brand_i_would_pay_more_for_mean'), ('TEMPTATIONS', 'CAT FOOD', 'directions_brand_attributes_offers_a_flavors_that_appeals_to_my_dogs_taste_mean'), ('TEMPTATIONS', 'CAT FOOD', 'directions_brand_attributes_provides_all_the_variety_my_cat_wants_mean'), ('TEMPTATIONS', 'CAT FOOD', 'directions_brand_attributes_understands_the_relationship_between_me_and_my_cat_mean'), ('TEMPTATIONS', 'CAT FOOD', 'directions_brand_attributes_understands_the_relationship_between_me_and_my_dog_mean')]\n",
      "('directions_awareness_total_awareness_net_mentions', np.float64(100.0), np.float64(0.0))\n",
      "('directions_awareness_unaided_awareness_net_mentions', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_always_seems_to_be_doing_something_new_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_costs_more_than_i_am_prepared_to_pay_mean_inverse', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_creates_excitement_and_eagerness_at_mealtime_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_creates_playful_moments_with_my_cat_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_has_a_taste_my_cat_enjoys_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_has_a_taste_my_dog_enjoys_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_has_craveable_treats_that_my_cat_comes_running_for_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_has_treats_i_could_feed_my_dog_everyday_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_has_treats_that_contain_wholesome_ingredients_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_helps_me_connect_with_my_dog_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_is_a_brand_i_do_not_trust_to_feed_to_my_pet_mean_inverse', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_is_a_brand_i_trust_more_than_others_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_is_a_brand_i_would_pay_more_for_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_is_a_brand_that_is_gaining_in_popularity_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_is_a_very_good_value_for_the_money_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_is_available_in_different_forms_for_different_occasions_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_is_easy_to_find_and_buy_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_is_often_available_on_promotion_or_deal_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_is_too_cheap_to_be_of_acceptable_quality_mean_inverse', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_offers_a_flavors_that_appeals_to_my_dogs_taste_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_offers_products_that_contain_real_natural_ingredients_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_provides_all_the_variety_my_cat_wants_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_understands_the_relationship_between_me_and_my_cat_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_attributes_understands_the_relationship_between_me_and_my_dog_mean', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_consideration_one_of_many_brands_i_would_consider_buying_net', np.float64(100.0), np.float64(0.0))\n",
      "('directions_brand_consideration_the_only_brand_i_would_consider_buying_net', np.float64(100.0), np.float64(0.0))\n",
      "('directions_funnel_metrics_advocacy_t2b_buyers', np.float64(100.0), np.float64(0.0))\n",
      "('directions_future_purchase_intent_definitely_would_buy_net', np.float64(100.0), np.float64(0.0))\n",
      "('directions_future_purchase_intent_probably_would_buy_net', np.float64(100.0), np.float64(0.0))\n",
      "('directions_positive_brand_trust', np.float64(100.0), np.float64(0.0))\n",
      "('directions_strategic_measures_brand_interest_index', np.float64(145.7032492), np.float64(52.59350532))\n",
      "('directions_strategic_measures_brand_love_index', np.float64(145.7032492), np.float64(52.59350532))\n",
      "('directions_strategic_measures_brand_loyalty_index', np.float64(145.7032492), np.float64(52.59350532))\n",
      "('neilsen_panel_value_per_occasion', np.float64(100.0), np.float64(0.0))\n",
      "('ratings_reviews_good_experience_percentage', np.float64(1.0), np.float64(0.0))\n",
      "('ratings_reviews_positive_ratings_percentage', np.float64(100.0), np.float64(0.0))\n",
      "('ratings_reviews_review_rating_average', np.float64(5.0), np.float64(0.0))\n",
      "('ratings_reviews_review_sentiment_score_average', np.float64(2.0), np.float64(0.0))\n",
      "('ratings_reviews_review_sentiment_score_health_benefits', np.float64(2.0), np.float64(0.0))\n",
      "('ratings_reviews_review_sentiment_score_ingredients', np.float64(2.0), np.float64(0.0))\n",
      "('ratings_reviews_review_sentiment_score_pet_enjoyment', np.float64(2.0), np.float64(0.0))\n",
      "('ratings_reviews_review_sentiment_score_value_for_the_money', np.float64(2.0), np.float64(0.0))\n",
      "('search_searchvolume_share', np.float64(1.0), np.float64(0.0))\n",
      "('social_percent_positive_neutral', np.float64(1.0), np.float64(0.0))\n",
      "('social_share_of_total_buzz_post', np.float64(100.0), np.float64(0.0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cilvo.simon\\AppData\\Local\\Temp\\ipykernel_28092\\88934075.py:267: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  scaled_df = melted_data.groupby('metric', group_keys=False).apply(apply_scaling)\n"
     ]
    }
   ],
   "source": [
    "#Data Preprocessing\n",
    "melted_df = pd.melt(\n",
    "    filtered_data,\n",
    "    id_vars=['date', 'brand', 'category'],  # Columns to keep as-is\n",
    "    var_name='metric',  # Name of the new column for melted variable names\n",
    "    value_name='value'  # Name of the new column for melted values\n",
    ")\n",
    "no_null_imputed_data = impute_groups(melted_df, ['brand', 'category', 'metric'], .5)\n",
    "scaled_data = scale_metrics(no_null_imputed_data, idv_list, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
